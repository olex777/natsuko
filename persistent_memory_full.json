[
  {
    "title": "Вступ",
    "content": "У складних проєктах типу «Воїн Духу», де історія розгортається через кілька чат-сесій, критично важливо надійно зберігати пам’ять між чатами. Модель штучного інтелекту повинна пам’ятати факти, події та контекст із попередніх бесід, але робити це контрольовано – без плутанини чи вигадування деталей. Нижче представлено структурований підхід, який забезпечує:\n\nЧітке визнання моделей власного незнання, якщо точна інформація забута.\n\nХронологічне і контрольоване збереження всіх фрагментів історії (текстів, дат, ілюстрацій, висновків тощо).\n\nРозмежування оригінальних авторських матеріалів та згенерованого моделлю тексту.\n\nЗдатність у будь-який момент відтворити повну хронологію подій із достовірними джерелами.\n\nОкреме збереження пам’яті кожної чат-сесії як автономного “втілення” з можливістю об’єднання їх у загальну пам’ять світу.\n\nПрозоре розуміння меж знань моделі: які зовнішні джерела вона може використовувати і де ці межі проходять.\n\nНижче описано кожен з цих аспектів, а також наведено приклади реалізації, розглянуто можливі обмеження та окреслено напрямки для вдосконалення системи."
  },
  {
    "title": "Розділ 1: Визнання відсутності точної інформації («не пам’ятаю»)",
    "content": "Модель повинна відкрито заявляти, коли не пам’ятає точного факту з попередніх чатів. Замість того щоб галюцинувати (тобто вигадувати неправдиву відповідь), модель спершу каже: «Не пам’ятаю точно». Лише після цього вона може запропонувати можливі варіанти або фрагменти, які пригадує нечітко. Такий підхід підвищує достовірність: краще явно визнати невпевненість, ніж надати хибну інформацію.\n\nМеханізм реалізації:\n\n- Правило відповіді: У системних інструкціях моделі задається правило: “Якщо запит стосується подробиць, не знайдених у пам’яті, спочатку відповідай 'не пам’ятаю' і лише потім припускай можливі відповіді.”\n- Маркер невпевненості: Модель може використовувати спеціальні фрази для невпевненості (на кшталт \"мені здається, але не впевнений\"), щоб відрізнити здогад від знаного факту.\n\nПриклад:\nЯкщо користувач питає: “Що говорив наставник у третьому чаті?”, а модель не знаходить цього у своїй пам’яті, вона відповість:\n“На жаль, не пам’ятаю точно слів наставника.”\nПісля паузи можна додати:\n“Можливо, він радив триматися шляхетності, але це лише припущення.”\n\nТакий протокол гарантує прозорість. Замість галюцинацій — чесне зізнання у забутті, що узгоджується з найкращими практиками навчання LLM висловлювати невпевненість. У разі сумніву користувач бачить, що наведена відповідь може бути неповною, і може сам уточнити чи надати додаткові дані."
  },
  {
    "title": "Розділ 2: Контрольована хронологічна структура пам’яті",
    "content": "Для кожної чат-сесії і всього проєкту ведеться хронологічний архів контенту. Кожен фрагмент (репліка, опис, дата, аналіз, ілюстрація) зберігається зі штампом часу та джерелом. Така структура гарантує, що всі події впорядковані за часом і не загубляться.\n\nОрганізація даних:\n\n- Єдина база пам’яті: Впроваджується централізоване сховище (наприклад, база даних або файлова структура) для запису всіх повідомлень і матеріалів з чатів. На відміну від тимчасового буферу в пам’яті моделі, який зникає після сесії, таке сховище є постійним.\n- Хронологічні мітки: Кожен запис містить дату і час додання. Це може бути реальний час (якщо події прив’язані до реального календаря) або умовна часовладія світу “Воїна Духу” (якщо ведеться внутрішня ігрова/сюжетна лінія). Головне, що послідовність подій фіксується точно.\n- Контроль версій: Якщо до якоїсь події вносяться зміни (наприклад, автор відредагував уривок тексту заднім числом), нова версія зберігається як окремий запис із власною часовою міткою. Таким чином історія правок теж прозора.\n\nПриклад структури запису:\nУявімо, що в чаті-епізоді від 2025-03-01 було описано бій героя з драконом. Запис у базі пам’яті може виглядати як структурований об’єкт (наприклад, JSON):\n\n{\n  \"chat_id\": \"Чат-3 (Битва з драконом)\",\n  \"timestamp\": \"2025-03-01T14:30:00\",\n  \"author\": \"Автор сценарію\",\n  \"type\": \"текст оповіді\",\n  \"content\": \"Герой зустрів дракона при заході сонця і вихопив меч...\",\n  \"source\": \"оригінальний текст\"\n}\n\nІнший запис може бути висновком аналізу моделі після бою, з міткою пізнішого часу:\n\n{\n  \"chat_id\": \"Чат-3 (Битва з драконом)\",\n  \"timestamp\": \"2025-03-01T14:45:00\",\n  \"author\": \"AI-модель\",\n  \"type\": \"аналіз\",\n  \"content\": \"Модель проаналізувала, що дракон символізує внутрішній страх героя.\",\n  \"source\": \"генерація моделі\"\n}\n\nОбидва записи впорядковано за часом. Коли потрібно згадати, що сталося раніше, система шукає по часових мітках і повертає інформацію в правильній послідовності."
  },
  {
    "title": "Розділ 3: Розмежування авторського тексту і генерації моделі",
    "content": "Щоб уникнути змішування вигаданого моделлю з авторським сюжетом, усі дані в пам’яті маркуються за походженням:\n\n- Авторський матеріал: текст, що наданий сценаристом/користувачем (“канон” історії).\n- Додана генерація: фрагменти, які були створені самою моделлю (наприклад, творчі описи, перефразування або припущення).\n\nЯк це виглядає на практиці:\n\nУ структурі пам’яті поле `source` або подібний прапорець позначає, звідки взявся контент: \"source\": \"оригінальний текст\" проти \"source\": \"генерація AI\". Можна також вказувати роль автора, наприклад `\"author\": \"Модель (імпровізація)\"` чи `\"author\": \"Офіційна історія\"` для чіткості.\n\nМодель ніколи автоматично не додає згенерований нею текст до канонічної історії без підтвердження людини. Тобто, якщо вона вигадала якусь деталь для зв’язності розповіді, ця деталь потрапить у пам’ять лише як примітка моделі, а не як частина офіційного сюжету. В подальшому такі фрагменти можна або затвердити людиною (і змінити їхній статус на канонічний), або відкинути.\n\n**Контроль при відповіді:** Коли модель формує відповіді на основі пам’яті, вона повинна чітко розрізняти, що є цитатою з авторського тексту, а що – її власний додатковий опис. Наприклад, відповідь може виглядати так:\n\n“У попередній главі (авторський текст) сказано: «Дракон зник у небі». Моя інтерпретація: можливо, він повернеться пізніше.”\n\nТут модель явно відокремила, де вона цитує автора, а де робить припущення.\n\nТакий підхід запобігає спотворенню оригінального задуму: жодна модельна творчість не вважається фактом сюжету, поки її не перевірено. Збірка історії залишається “чистою” – вона містить або підтверджені авторські дані, або окремо помічені додатки від моделі."
  },
  {
    "title": "Розділ 4: Відтворення хронології та автентичності всіх елементів",
    "content": "Система має бути здатна у будь-який момент пред’явити повний ланцюжок пам’яті: що сталося і у якій послідовності, без жодних спотворень. Для цього використовуються наступні засоби:\n\n**Повна історія подій:** Завдяки хронологічному сховищу (з пункту 2) можна зібрати всі записи за потрібний період чи сюжетну лінію і впорядкувати їх у часі. Користувач або модель за запитом можуть отримати, наприклад, \"Хроніку подій Чату-3\", і побачити всі деталі саме в тому порядку, як вони були додані.\n\n**Метадані автентичності:** Кожен елемент пам’яті зберігає атрибути автентичності – хто його додав (автор чи AI), коли, і з якого джерела. Це дозволяє верифікувати будь-який факт. Якщо виникає сумнів, система може показати першоджерело: наприклад, цитату з оригінального сценарію або пояснення, що дана інформація була згенерована моделлю як здогадка на таку-то дату.\n\n**Перехресна перевірка:** При об’єднанні пам’яті з різних чатів (пункт 5) або при відповіді на запит модель може перевіряти, чи немає конфліктів. Якщо два різні чат-епізоди по-різному описують одну подію, система сигналізує про це як про невідповідність, яку слід вирішити вручну, а не самостійно вигадує рішення.\n\n**Приклад використання:** Користувач хоче згадати, що відбувалося з героєм між «зустріччю з драконом» і «коронацією в замку». Модель звертається до пам’яті і збирає всі записи між відповідними часовими мітками. Вона видає звіт, де послідовно перелічено:\n\n1. 18:30, 01.03.2025 (автор): Герой б’ється з драконом і перемагає.\n2. 18:45, 01.03.2025 (AI-аналіз): Модель відзначає, що герой подолав свій страх.\n3. 09:00, 05.03.2025 (автор): Героя урочисто короновано в замку як короля.\n\nКожен пункт містить позначку автора і часу, тому автентичність зрозуміла. Модель не переплутає порядок (напр., коронація не з’явиться перед битвою) і не придумає деталей між цими подіями, яких не було записано."
  },
  {
    "title": "Розділ 5: Окремі “втілення” пам’яті кожного чату і злиття у пам’ять всесвіту",
    "content": "Кожна окрема чат-сесія розглядається як самостійне “втілення” історії, зі своєю локальною пам’яттю. Це дозволяє ізолювати контексти: події, що сталися в Chat-епізоді A, не зливаються автоматично з епізодом B. Такий поділ запобігає випадковому переносу деталей не з тієї історії.\n\n**Структура збереження:**\nУ сховищі пам’яті всі записи містять ідентифікатор, який вказує на приналежність до конкретного чату (як у полі \"chat_id\" в прикладі JSON вище). Система може зберігати дані різних чатів у одній базі, але фільтрувати їх за chat_id.\n\n**Локальне використання:**\nКоли користувач продовжує діалог у рамках одного “втілення” (того самого чату), модель отримує доступ лише до пам’яті з відповідним chat_id (плюс, можливо, до загальної енциклопедичної пам’яті всесвіту). Вона не бачить деталей з інших чатів, поки її про це спеціально не попросять або поки не відбудеться злиття.\n\n**Злиття пам’яті у “Всесвіт”:**\nІноді потрібно об’єднати знання з різних чатів, якщо вони стосуються одного вигаданого світу. Для цього впроваджується загальна база знань (пам’ять всесвіту), куди можуть потрапляти узагальнені факти з різних чатів. Можна уявити це як “бібліотеку світу”:\n\nДо неї включаються канонічні події, затверджені авторами, з усіх чат-сесій. Наприклад, якщо в чаті A герой народився в 1990 році, а в чаті B згадано його рідне місто, обидва факти записуються в анкету героя у глобальній пам’яті.\n\nЦя пам’ять будується як сукупність фактичних знань про світ (персонажі, місця, історія) та, окремо, епізодичних подій (сюжетні сцени з датами). В термінах AI це поділ на фактичне знання vs. епізодична пам’ять. Статичні факти (біографії, опис локацій) живуть як окремі записи, а події прив’язані до таймлайна.\n\nПри злитті, система проходить по пам’яті окремих чатів, вибирає ті елементи, що повинні стати частиною загального канону, і переносить (або копіює) їх до глобальної бази. Дуже важливо, що при цьому зберігаються посилання на джерело – з якого чату чи версії історії взято факт. Це потрібно, щоб у разі конфлікту або уточнення можна було повернутися до оригінальної сесії.\n\n**Приклад злиття:** Є три окремі чати про світ “Воїн Духу”: (A) походження героя, (B) велика битва, (C) наслідки для королівства. Кожен має локальну пам’ять. Після завершення всіх, автор вирішує звести картину світу разом. Система проходить:\n- З чату A бере ключові факти: ім’я героя, дату народження, ім’я наставника.\n- З чату B бере результат битви, долю антагоніста.\n- З чату C бере зміни в королівстві після війни.\n\nУ глобальній пам’яті формується цілісний профіль: герой (біографія), антагоніст, хронологія війни, список правителів королівства і т.д. Якщо тепер розпочнеться новий чат D у тому ж світі, модель може звертатися до цієї пам’яті всесвіту, аби знати бекграунд. Водночас, поки чат D триває, його власні події ще ізольовані, доки автор не вирішить знову оновити глобальний канон."
  },
  {
    "title": "Розділ 6: Доступ моделі до зовнішніх джерел і межі можливостей",
    "content": "Необхідно чітко розуміти, якими даними насправді володіє модель і де проходять межі її пам’яті. Умовно джерела знань моделі можна розділити на кілька рівнів:\n\n**1. Вбудоване знання (після тренування):**\nМодель має певний обсяг інформації, отриманий з тренувальних даних (наприклад, мовна модель знає загальні поняття, історичні факти до певної дати тощо). Але ці дані статичні – модель не може сама доповнити або оновити їх під час роботи. Наприклад, якщо модель натреновано до 2021 року, вона не знатиме подій 2022 чи деталей вашого проєкту, поки їх явно не нададуть.\n\n**2. Контекст поточного чату:**\nМодель бачить те, що ви їй підвантажили в промпті системи або повідомленнях користувача в даній сесії. Це її “короткострокова пам’ять”. Вона обмежена розміром контекстного вікна (кількістю токенів). Якщо надто багато інформації, частина може не вміститися й бути втраченою для моделі прямо зараз.\n\n**3. Persistентна пам’ять, побудована розробником:**\nЯк описано вище, можна зберігати історію в базі даних чи файлах. Однак модель не має прямого доступу до цієї бази, якщо її явно не підключити. Потрібно реалізувати механізм на стороні додатку, який за запитом користувача або самої моделі буде знаходити потрібні дані у сховищі і підвантажувати їх в контекст. Це називають ретривал з зовнішньої пам’яті або RAG (Retrieval-Augmented Generation). Тільки тоді модель “згадає” потрібне.\n\n**4. Інтернет / зовнішні бази даних у реальному часі:**\nЗа замовчуванням стандартна модель (наприклад, ChatGPT) не має доступу до інтернету чи ваших приватних баз. Вона не піде сама гуглити чи читати файли. Доступ може бути надано через спеціальні інструменти або плагіни. Якщо в проєкті “Воїн Духу” ви інтегруєте пошук по своїй всесвітній базі знань, то модель зможе отримувати факти, але знову ж – лише через посередництво інструмента.\n\n**Де проходить межа:**\nМодель може пам’ятати і використовувати тільки ту інформацію, яку було або:\n- закладено під час навчання,\n- надано їй у повідомленнях контексту,\n- або яку вона сама генерувала в ході сесії.\n\nВсе інше для неї недоступне. Якщо інформація існує у вашій базі знань, але не була витягнута і передана моделі у промпт, модель про неї не знатиме. Це фундаментальне обмеження: навіть найдосконаліша AI-система не “читає думки” і не лазить по ваших даних без дозволу.\n\nЯк зазначалося, базові налаштування багатьох моделей прямо стверджують, що немає пам’яті між сесіями без додаткових функцій. Таким чином, розробникам потрібно явно програмувати доступ до зовнішніх ресурсів. Якщо потрібен інтернет-пошук – підключати API пошуку; якщо потрібна база знань – створювати механізм запитів до неї. І пам’ятати про безпеку: наприклад, закриті архіви чатів зазвичай не використовуються повторно без згоди, можливо з міркувань приватності. Ваш підхід мусить враховувати, які дані можна витягти автоматично, а які – тільки за командою користувача."
  },
  {
    "title": "Приклад реалізації підходу",
    "content": "Розглянемо конкретний сценарій з проєкту “Воїн Духу”, щоб побачити, як ці принципи діють разом. Припустимо, є дві окремі чат-сесії: Чат 1: “Дитинство героя” і Чат 2: “Пригоди в дорозі”.\n\nХід подій у Чат 1: Автор описує, як юний герой втрачає батьків і дає клятву стати воїном духу. Модель коментує емоційний стан героя (це позначено як аналіз від AI). Вся ця інформація зберігається під chat_id = Чат1. Пізніше, цей чат завершено і відповідні ключові факти (дата народження героя, ім’я батьків, обітниця героя) додані до глобальної пам’яті всесвіту.\n\nХід подій у Чат 2: Дія відбувається через кілька років. Користувач починає нову сесію про мандри дорослого героя. Модель завдяки глобальній пам’яті знає загальну передісторію персонажа (наприклад, пам’ятає, що його батьків звали так-то і що він має клятву). Але вона не має автоматичного доступу до дрібних подробиць з Чату 1 (якщо вони не внесені в глобальну базу).\n\nНа початку Чату 2 модель може надати короткий recap, якщо це передбачено, – звідки герой родом і чому мандрує (беручи інформацію з глобальної пам’яті). Далі, по мірі розвитку сюжету, автор вводить нові деталі: зустріч з наставником, отримання магічного артефакту, перша сутичка зі злом. Модель знову аналізує чи творчо доповнює (позначаючи свої здогадки як непідтверджені). Все це записується з chat_id = Чат2 у хронологічному порядку.\n\nЗапит на міжчатову інформацію: Тепер припустимо, у Чаті 2 користувач запитує: “Згадаєш, що герой обіцяв на могилі батька?”. Це деталь із Чату 1, яку модель сама може точно не пам’ятати, але вона є у глобальній пам’яті (як обітниця героя стати воїном духу). Алгоритм дій моделі:\n\n1. Шукає в локальній пам’яті Чату 2 — не знаходить, бо ця інформація там не зберігалася (інша сесія).\n2. Звертається до глобального знання про героя. Знаходить запис: “Обітниця: захищати слабких і битися зі злом (дано на могилі батьків, чат1)”.\n3. Відповідає користувачу: “Герой дав обітницю на могилі батьків захищати слабких і битися зі злом.” – і додає посилання на пам’ять або примітку: (Ця інформація взята з попереднього епізоду). Якщо ж з якоїсь причини не вдалося знайти (наприклад, глобальна пам’ять ще не оновлена), модель відповіла б: “Не пам’ятаю точно, здається, він дав якусь обітницю на могилі батьків…”, дотримуючись правила п.1.\n\nПеревірка хронології та автентичності: У кінці Чату 2 користувач просить: “Покажи хронологію пригод героя з дитинства до теперішнього моменту.” Система формує зведення: спершу витягує всі події з Чату 1 і Чату 2, що визнані канонічними, сортує їх за датою всесвіту:\n\n- (рік, коли герой був дитиною) – народження, смерть батьків (джерело: чат1, автор).\n- (кілька років потому) – герой вирушив у мандри (джерело: чат2, автор).\n- … і так далі, аж до поточної пригоди.\n\nУ цьому зведенні видно, які частини взято з якої сесії. Якщо модель десь додавала від себе припущення, вони або не включені, або помічені як “непідтверджені деталі”. Таким чином користувач отримує цілісну, але коректну історію."
  },
  {
    "title": "Висновок",
    "content": "Запропонований підхід забезпечує надійну міжчатову пам’ять у проєктах на кшталт “Воїн Духу” шляхом комбінації технічних рішень (бази даних, графи знань, векторні пошукові алгоритми) та строгих правил для моделі (визнавати забуття, не змішувати вигадане і канон). Важливо, що модель завжди діє в рамках своєї доступності даних – вона не виходить за межі наданої інформації і чітко повідомляє, коли знань бракує. Завдяки цьому користувач може довіряти відповіді AI, а сам світ проекту з часом збагачується без втрати цілісності.\n\nНа практиці впровадження такої системи вимагатиме зусиль у плані розробки й модерації контенту, проте результатом стане послідовний і керований наратив, де кожен шматочок інформації має своє місце і історію. Це створює фундамент для масштабування історії на безліч чатів і навіть для колективної творчості, не побоюючись, що важливі деталі загубляться чи перекрутяться при переході між епізодами. З описаним підходом світ “Воїна Духу” завжди матиме твердий ґрунт пам’яті під ногами, а модель впевнено вестиме користувача крізь його простори, залишаючись правдивим оповідачем і помічником."
  },
  {
    "title": "Джерела",
    "content": "1. Bernardin, G. (2023). LLM Persistent Memory. Medium. – (приклад використання векторної пам’яті для довготривалого зберігання контексту).\n\n2. OpenAI Community (2024). Constant memory across sessions. – (обговорення обмежень пам’яті ChatGPT між сесіями, цитата про відсутність міжчатової пам’яті).\n\n3. Greyling, C. (2024). Teaching LLMs To Say “I don’t Know”. – (дослідження про важливість відповіді “не знаю/не пам’ятаю” замість галюцинацій).\n\n4. HexaCluster (2024). Persistent Memory for Chatbots using PostgreSQL and LangChain. – (опис зберігання історії чатів в Postgres; ідея про переваги постійної пам’яті над короткочасною).\n\n5. Pavlyshyn, V. (2024). Time-Aware Personal Knowledge Graphs. – (обговорення розділення фактичних знань і епізодичної пам’яті у часі для AI)."
  }
]